{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from rich import print\n",
    "from getpass import getpass\n",
    "\n",
    "oai_api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=oai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling with `instructor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "ins_client = instructor.from_openai(\n",
    "    client, mode=instructor.Mode.RESPONSES_TOOLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `tool_calling` is a very simple technique. \n",
    "\n",
    "**It's like this:**\n",
    "1. üë§ **You ask** something the AI doesn't know right now\n",
    "2. ü§ñ **AI realizes** \"I need help with this!\"\n",
    "3. üîß **AI grabs the right tool** (like a web search app)\n",
    "4. üå§Ô∏è **Tool gives the answer** back to AI\n",
    "5. ü§ñ **AI tells you** in a nice way!\n",
    "\n",
    "Let's go to OpenAI and check tool calling in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "How does it translate to code?\n",
    "\n",
    "(Using the stock example in `instructor`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:59.293 POST api.openai.com/v1/responses\n",
      "15:21:01.499 Reading response body\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    id: int\n",
    "    url: str\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    citations: list[Citation]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "response = ins_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"Who won the Test world cup in 2025?\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    response_model=Summary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">citations</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://www.icc-cricket.com/test-world-cup-2025/results'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://en.wikipedia.org/wiki/2025_ICC_Test_Championship'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The 2025 ICC Test World Cup winner is determined based on the ICC Test Championship final results held</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in 2025.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcitations\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://www.icc-cricket.com/test-world-cup-2025/results'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://en.wikipedia.org/wiki/2025_ICC_Test_Championship'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33msummary\u001b[0m=\u001b[32m'The 2025 ICC Test World Cup winner is determined based on the ICC Test Championship final results held\u001b[0m\n",
       "\u001b[32min 2025.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfire_token = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=384356;https://logfire-us.pydantic.dev/pratos/build-w-ai\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/pratos/build-w-ai\u001b[0m\u001b]8;;\u001b\\\n",
      "Currently retrying 1 failed export(s)\n",
      "Currently retrying 1 failed export(s)\n"
     ]
    }
   ],
   "source": [
    "import logfire\n",
    "\n",
    "logfire.configure(token=logfire_token)\n",
    "logfire.instrument_pydantic_ai()\n",
    "logfire.instrument_httpx(capture_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:45.163 POST api.openai.com/v1/responses\n",
      "10:44:51.396 Reading response body\n"
     ]
    }
   ],
   "source": [
    "response = ins_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What are the LLMs that have tool calling capabilities in the market?\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    response_model=Summary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">citations</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://ai.googleblog.com/2023/05/introducing-bard-google-ai-search-experience.html'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openai.com/blog/gpt-4-api-announcement'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://www.microsoft.com/en-us/research/blog/how-to-build-ai-applications-with-openai-and-azure-c</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ognitive-services/'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/blog/toolformer'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://www.anthropic.com/index/introducing-claude'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Several large language models (LLMs) currently available in the market support tool calling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities. These include Google Bard, which integrates external tools to enhance search and information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval; OpenAI's GPT-4, which supports API-based tool integrations; Microsoft's AI models on Azure that combine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs with cognitive services for extended tool functionalities; Meta's Toolformer model that is designed to use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external tools effectively; and Anthropic's Claude, which incorporates safe tool usage features. These LLMs enable </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhanced interactivity by calling external APIs, plugins, or services to perform complex tasks and retrieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">real-time information.\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcitations\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://ai.googleblog.com/2023/05/introducing-bard-google-ai-search-experience.html'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://openai.com/blog/gpt-4-api-announcement'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "            \u001b[33murl\u001b[0m=\u001b[32m'https://www.microsoft.com/en-us/research/blog/how-to-build-ai-applications-with-openai-and-azure-c\u001b[0m\n",
       "\u001b[32mognitive-services/'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://huggingface.co/blog/toolformer'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://www.anthropic.com/index/introducing-claude'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33msummary\u001b[0m=\u001b[32m\"Several\u001b[0m\u001b[32m large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m currently available in the market support tool calling \u001b[0m\n",
       "\u001b[32mcapabilities. These include Google Bard, which integrates external tools to enhance search and information \u001b[0m\n",
       "\u001b[32mretrieval; OpenAI's GPT-4, which supports API-based tool integrations; Microsoft's AI models on Azure that combine \u001b[0m\n",
       "\u001b[32mLLMs with cognitive services for extended tool functionalities; Meta's Toolformer model that is designed to use \u001b[0m\n",
       "\u001b[32mexternal tools effectively; and Anthropic's Claude, which incorporates safe tool usage features. These LLMs enable \u001b[0m\n",
       "\u001b[32menhanced interactivity by calling external APIs, plugins, or services to perform complex tasks and retrieve \u001b[0m\n",
       "\u001b[32mreal-time information.\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:09:02.487 POST api.openai.com/v1/responses\n",
      "11:09:06.072 Reading response body\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summary</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">citations</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Citation</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://www.timeanddate.com/worldclock/india/mumbai'</span><span style=\"font-weight: bold\">)]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'To know the current time in Mumbai, India, you can check a reliable world clock or time zone website </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as timeanddate.com, which provides real-time updates for cities around the globe.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcitations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mCitation\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33murl\u001b[0m=\u001b[32m'https://www.timeanddate.com/worldclock/india/mumbai'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33msummary\u001b[0m=\u001b[32m'To know the current time in Mumbai, India, you can check a reliable world clock or time zone website \u001b[0m\n",
       "\u001b[32msuch as timeanddate.com, which provides real-time updates for cities around the globe.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ins_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What is the current time in Mumbai?\",\n",
    "    # tools=[{\"type\": \"web_search_preview\"}],\n",
    "    response_model=Summary,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:09:41.945 POST api.openai.com/v1/responses\n",
      "11:10:11.076 Reading response body\n"
     ]
    }
   ],
   "source": [
    "class TimeInfo(BaseModel):\n",
    "    time: str\n",
    "    timezone: str\n",
    "\n",
    "\n",
    "response = ins_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What is the current time in Mumbai?\",\n",
    "    response_model=TimeInfo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:10:11.270 POST api.openai.com/v1/responses\n",
      "11:10:19.314 Reading response body\n"
     ]
    }
   ],
   "source": [
    "response = ins_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=\"What is the current time in Mumbai?\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    response_model=Summary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We won't go into the OpenAI SDK code for tool calling, the json spec to read is confusing for a first timer.\n",
    "\n",
    "What about external tools? \n",
    "\n",
    "- `instructor` sadly doesn't provide any good way to solve that.\n",
    "\n",
    "There are other frameworks that let you build out stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building agents with `pydantic-ai\n",
    "\n",
    "Why `pydantic-ai`?\n",
    "\n",
    "- `instructor` doesn't have a good api around custom tool calls. It does one thing well and you could mix and match with newer \"agentic frameworks\".\n",
    "- `langchain` or `llamaindex` are much much better in terms of features and support.\n",
    "- But there's still some learning curve and the API is frankly not my taste (my hot take).\n",
    "- `pydantic-ai` offers the right balance where I can explain the fundamentals and we can grow out from there.\n",
    "- There's other libraries as well -> `agno`, `marvin`, etc. You can choose whatever you need to. Too many to try out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:22:47.441 agent run\n",
      "15:22:47.442   chat gpt-4o-mini\n",
      "15:22:47.445     POST api.openai.com/v1/chat/completions\n",
      "15:22:48.818 Reading response body\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The square root of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102001</span> is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">319</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The square root of \u001b[1;36m102001\u001b[0m is \u001b[1;36m319\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "number = 102001\n",
    "\n",
    "model = OpenAIModel(\"gpt-4o-mini\", provider=OpenAIProvider(api_key=oai_api_key))\n",
    "agent = Agent(\n",
    "    model,\n",
    "    system_prompt=\"Be concise, reply with one sentence.\",\n",
    ")\n",
    "\n",
    "prompt = f\"Can you find me square root of {number}?\"\n",
    "\n",
    "result = await agent.run(prompt)\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "class LocationInfo(BaseModel):\n",
    "    place: str\n",
    "    temperature: Optional[float]\n",
    "    # time: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Deps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m agent = Agent(\n\u001b[32m      2\u001b[39m     model,\n\u001b[32m      3\u001b[39m     instructions=(\u001b[33m\"\u001b[39m\u001b[33mBe concise,reply with one sentence\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     deps_type=\u001b[43mDeps\u001b[49m,\n\u001b[32m      5\u001b[39m     output_type=LocationInfo,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'Deps' is not defined"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    model,\n",
    "    instructions=(\"Be concise,reply with one sentence\"),\n",
    "    deps_type=Deps,\n",
    "    output_type=LocationInfo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
